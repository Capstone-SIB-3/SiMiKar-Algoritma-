# -*- coding: utf-8 -*-
"""Cotent Based_Sistem Rekomendasi Minat Karir

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19JwVQZOO1hzbCdV3rBVB2CtbgrY_7FKD
"""

# Commented out IPython magic to ensure Python compatibility.
# Untuk pengolahan data
from google.colab import files 
import numpy as np
import pandas as pd
from sklearn.utils import resample 
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder


# Untuk visualisasi data
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd

jobs = pd.read_csv('/content/techloker.csv', encoding = 'ISO-8859-1')

jobs.head(10)

jobs

jobs.drop('link',axis=1,inplace= True)
jobs.drop('nama_perusahaan',axis=1,inplace= True)
jobs.drop('lokasi_perusahaan',axis=1,inplace= True)

jobs.head(10)

jobs.info()

print('Banyak data: ', len(jobs.jenis_pekerjaan.unique()))
print('Jenis Pekerjaan : ', jobs.jenis_pekerjaan.unique())

print('Banyak data: ', len(jobs.kemampuan.unique()))
print('Jenis Kemampuan yang tersedia : ', jobs.kemampuan.unique())

# Cek missing value dengan fungsi isnull()
jobs.isnull().sum()

# Membersihkan missing value dengan fungsi dropna()
jobs_clean = jobs.dropna()
jobs_clean

# Cek missing value dengan fungsi isnull()
jobs_clean.isnull().sum()

jobs_clean.info()

# Mengurutkan resto berdasarkan kemampuan kemudian memasukkannya ke dalam variabel fix_jobs
fix_jobs = jobs_clean.sort_values('kemampuan', ascending=True)
fix_jobs

# Mengecek berapa jumlah fix_jobs
len(fix_jobs.kemampuan.unique())

# Mengecek kategori kemampuan yang unik
fix_jobs.kemampuan.unique()

# Membuang data duplikat pada variabel preparation
preparation_jobs = fix_jobs.drop_duplicates('kemampuan')
preparation_jobs

# Mengonversi data series ‘jenis_pekerjaan’ menjadi dalam bentuk list
jenis_jobs = preparation_jobs['jenis_pekerjaan'].tolist()

 
# Mengonversi data series ‘kemampuan’ menjadi dalam bentuk list
kemampuan_jobs = preparation_jobs['kemampuan'].tolist()
 
print(len(jenis_jobs))

print(len(kemampuan_jobs))

# Membuat dictionary untuk data ‘jenis_pekerjaan’, ‘kemampuan’
jobs_new = pd.DataFrame({
    'Jenis_Pekerjaan': jenis_jobs,
    'Kemampuan': kemampuan_jobs
})
jobs_new

jobs_recomend = jobs_new
jobs_recomend.sample(5)

jobs_recomend.head(10)

value = pd.DataFrame(jobs_recomend['Kemampuan'].value_counts().reset_index().values, columns = ['Kemampuan','count'])
value.head(10)

value = pd.DataFrame(jobs_recomend['Jenis_Pekerjaan'].value_counts().reset_index().values, columns = ['Jenis_Pekerjaan','count'])
value.head(10)

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data kemampuan 
tf.fit(jobs_recomend['Kemampuan'])


# Mapping array dari fitur index integer  ke fitur nama 
tf.get_feature_names()

# Melakukan fit lalu ditransformasikan ke bentuk matriks 
tfidf_matrix = tf.fit_transform(jobs_recomend['Kemampuan'])

# Melihat ukuran matriks tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis get_names
# Baris diisi dengan nama Kemampuan
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=jobs_recomend.Kemampuan
).sample(22, axis=1).sample(10, axis=0)

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa movie
cosine_sim_df = pd.DataFrame(cosine_sim, index=jobs_recomend['Kemampuan'], columns=jobs_recomend['Jenis_Pekerjaan'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap kemampuan
cosine_sim_df.sample(10, axis=1).sample(20, axis=0)

def jobs_recommendations(skill, similarity_data=cosine_sim_df, items=jobs_recomend[['Kemampuan','Jenis_Pekerjaan']], k=10):
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    index = similarity_data.loc[skill].to_numpy().argpartition(
        range(-1,-k, -1))
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    # Drop kemampuan agar kemampuan yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(skill, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

jobs_recommendations(jobs_recomend.Kemampuan['Golang, Backend Development, SQL Server, MySQL'])

jobs_recommendations(jobs_recomend.Kemampuan[3])

jobs_recommendations

jobs_recomend[jobs_recomend.Kemampuan.eq('Laravel, PHP, Vue.js')]

jobs_recomend[jobs_recomend.Jenis_Pekerjaan.eq('Fullstack Engineer')]

indices = pd.Series(index = jobs_recomend['Jenis_Pekerjaan'], data = jobs_recomend.index).drop_duplicates()
indices.head()

rekomendasi = pd.DataFrame(jobs_recommendations('Analytics, Data Science, Data Analysis'))
rekomendasi

value = pd.DataFrame(jobs_recomend['Kemampuan'].value_counts().reset_index().values, columns = ['Kemampuan','count'])
value.head(10)