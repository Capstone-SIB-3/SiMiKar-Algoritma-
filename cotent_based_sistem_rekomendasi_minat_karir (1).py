# -*- coding: utf-8 -*-
"""Cotent Based_Sistem Rekomendasi Minat Karir

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19JwVQZOO1hzbCdV3rBVB2CtbgrY_7FKD
"""

# Commented out IPython magic to ensure Python compatibility.
# Untuk pengolahan data
from google.colab import files 
import numpy as np
import pandas as pd
from sklearn.utils import resample 
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder


# Untuk visualisasi data
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd

jobs = pd.read_csv('/content/techloker.csv', encoding = 'ISO-8859-1')

jobs.head(10)

jobs

"""## Menghapus kolom yang tidak digunakan """

jobs.drop('link',axis=1,inplace= True)
jobs.drop('nama_perusahaan',axis=1,inplace= True)
jobs.drop('lokasi_perusahaan',axis=1,inplace= True)

"""## Menampilkan 10 sample teratas dataset

"""

jobs.head(10)

"""# Menampilkan jumlah entry unik berdasarkan kemampuan dan jenis_pekerjaan"""



print('Banyak data: ', len(jobs.jenis_pekerjaan.unique()))
print('Jenis Pekerjaan : ', jobs.jenis_pekerjaan.unique())

print('Banyak data: ', len(jobs.kemampuan.unique()))
print('Jenis Kemampuan yang tersedia : ', jobs.kemampuan.unique())

"""## Mengecek missing value"""

# Cek missing value dengan fungsi isnull()
jobs.isnull().sum()

"""## Membersihkan missing value"""

# Membersihkan missing value dengan fungsi dropna()
jobs_clean = jobs.dropna()
jobs_clean.head(10)

"""## Mengecek kembali missing value"""

# Cek missing value dengan fungsi isnull()
jobs_clean.isnull().sum()

"""## Menampilkan info dataset"""

jobs_clean.info()

"""## Mengurutkan jobs berdasarkan kemampuan kemudian memasukkannya ke dalam variabel fix_jobs"""

# Mengurutkan kemampuan berdasarkan kemampuan kemudian memasukkannya ke dalam variabel fix_jobs
fix_jobs = jobs_clean.sort_values('kemampuan', ascending=True)
fix_jobs

"""## Mengecek berapa jumlah fix_jobs"""

# Mengecek berapa jumlah fix_jobs
len(fix_jobs.kemampuan.unique())

"""## # Mengecek kategori kemampuan yang unik"""

# Mengecek kategori kemampuan yang unik
fix_jobs.kemampuan.unique()

"""## # Membuang data duplikat pada variabel preparation"""

# Membuang data duplikat pada variabel preparation
preparation_jobs = fix_jobs.drop_duplicates('kemampuan')
preparation_jobs

"""# Mengonversi data series jenis pekerjaan dan kemampuan menjadi dalam bentuk list"""

# Mengonversi data series ‘jenis_pekerjaan’ menjadi dalam bentuk list
jenis_jobs = preparation_jobs['jenis_pekerjaan'].tolist()

 
# Mengonversi data series ‘kemampuan’ menjadi dalam bentuk list
kemampuan_jobs = preparation_jobs['kemampuan'].tolist()
 
print(len(jenis_jobs))

print(len(kemampuan_jobs))

"""# Membuat dictionary untuk data jenis pekerjaan dan kemampuan"""

# Membuat dictionary untuk data ‘jenis_pekerjaan’, ‘kemampuan’
jobs_new = pd.DataFrame({
    'Jenis_Pekerjaan': jenis_jobs,
    'Kemampuan': kemampuan_jobs
})
jobs_new

"""# Memasukkan dataframe jobs_new kedalam variable jobs_recomend dan berikan 5 sample teratas"""

jobs_recomend = jobs_new
jobs_recomend.sample(5)

"""# Menggunakan teknik TF-IDF Vectorizer yang digunakan untuk untuk menemukan representasi fitur penting dari setiap kategori kemampuan"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data kemampuan 
tf.fit(jobs_recomend['Kemampuan'])


# Mapping array dari fitur index integer  ke fitur nama 
tf.get_feature_names()

"""## Melakukan fit model setelah itu akan ditransformasikan kedalam matriks kemudian akan dilakukan pengecekan ukuran matriks"""

# Melakukan fit lalu ditransformasikan ke bentuk matriks 
tfidf_matrix = tf.fit_transform(jobs_recomend['Kemampuan'])

# Melihat ukuran matriks tfidf
tfidf_matrix.shape

"""## Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""## Membuat dataframe untuk melihat tf-idf matrix untuk melihat korelasi antara jenis pekerjaan dan kemampuan"""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis get_names
# Baris diisi dengan nama Kemampuan
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=jobs_recomend.Jenis_Pekerjaan
).sample(10, axis=1).sample(10, axis=0)

"""## Menghitung cosine similarity pada matrix tf-idf"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""## Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa jenis pekerjaan dan kemampuan"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa movie
cosine_sim_df = pd.DataFrame(cosine_sim, index=jobs_recomend['Kemampuan'], columns=jobs_recomend['Jenis_Pekerjaan'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap kemampuan
cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""## Melihat similarity matrix pada setiap kemampuan dengan fungsi jobs_recommendations"""

def jobs_recommendations(Kemampuan, similarity_data=cosine_sim_df, items=jobs_recomend[['Jenis_Pekerjaan', 'Kemampuan']], k=10):
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    index = similarity_data.loc[Kemampuan].to_numpy().argpartition(
        range(-1,-k,-1))
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    # Drop kemampuan agar kemampuan yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(Kemampuan, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

jobs_recommendations

"""# Rekomendasi berdasarkan kemampuan"""

jobs_recommendations('Management, Microsoft, Communication Skills')

jobs_recommendations(jobs_recomend.Kemampuan[3])

"""# Ini hanya memanggil dari dataset """

jobs_recomend[jobs_recomend.Kemampuan.eq('Laravel, PHP, Vue.js')]

jobs_recomend[jobs_recomend.Jenis_Pekerjaan.eq('Fullstack Engineer')]

"""## list Rekomendasi berdasarkan jenis pekerjaan yang mirip"""

indices = pd.Series(index = jobs_recomend['Jenis_Pekerjaan'], data = jobs_recomend.index).drop_duplicates()
indices.head()

"""## list jumlah kemampuan yang mirip atau serupa"""

value = pd.DataFrame(jobs_recomend['Kemampuan'].value_counts().reset_index().values, columns = ['Kemampuan','count'])
value.head(10)

"""## List rekomendasi berdasarkan Kemiripan Kemampuan"""

rekomendasi = pd.DataFrame(jobs_recommendations('Laravel, PHP, Vue.js'))
rekomendasi

"""# Convert Hasilnya"""

rekomendasi.to_pickle('modelJobs')

cosine_sim_df.to_pickle('MyModel')

cosine_sim_df.to_csv('Mytech.csv')

"""# Evaluasi """

TP = 5 #jumlah prediksi benar untuk genre yang mirip atau serupa
FP = 0 #jumlah prediksi salah untuk genre yang mirip atau serupa

Precision = TP/(TP+FP)
print("{0:.0%}".format(Precision))